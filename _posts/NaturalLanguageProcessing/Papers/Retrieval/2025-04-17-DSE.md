---
layout: post
title: Unifying Multimodal Retrieval via Document Screenshot Embedding
subtitle: DES
category: RAG
tags: [LLM, RAG]
permalink: /2025/04/17/DSE/
css : /css/ForYouTubeByHyun.css
bigimg: 
  - "/img/Image/BigImages/carmel.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/monterey.jpg" : "Monterey, CA (2016)"
  - "/img/Image/BigImages/stanford_dish.jpg" : "Stanford Dish, CA (2016)"
  - "/img/Image/BigImages/marian_beach_in_sanfran.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/carmel2.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/marina.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/sanfrancisco.jpg" : "San Francisco, CA (2016)"
  
---

This post is a brief summary about the paper that I read for my study and curiosity, so I shortly arrange the content of the paper, titled [Unifying Multimodal Retrieval via Document Screenshot Embedding (Ma et al. EMNLP 2024)](https://aclanthology.org/2024.emnlp-main.373/), that I read and studied. 

{% include MathJax.html %}


![Ma et al. EMNLP 2024](/img/Image/NaturalLanguageProcessing/Papers/Retrieval/2025-04-17-DSE/DSE_01.png)

![Ma et al. EMNLP 2024](/img/Image/NaturalLanguageProcessing/Papers/Retrieval/2025-04-17-DSE/DSE_02.png)


For detailed experiment and explanation, refer to the paper, titled [Unifying Multimodal Retrieval via Document Screenshot Embedding (Ma et al. EMNLP 2024)](https://aclanthology.org/2024.emnlp-main.373/)

<div class="alert alert-info" role="alert"><i class="fa fa-info-circle"></i> <b>Note(Abstract): </b>
In the real world, documents are organized in different formats and varied modalities. Traditional retrieval pipelines require tailored document parsing techniques and content extraction modules to prepare input for indexing. This process is tedious, prone to errors, and has information loss. To this end, we propose Document Screenshot Embedding (DSE), a novel retrieval paradigm that regards document screenshots as a unified input format, which does not require any content extraction preprocess and preserves all the information in a document (e.g., text, image and layout). DSE leverages a large vision-language model to directly encode document screenshots into dense representations for retrieval. To evaluate our method, we first craft the dataset of Wiki-SS, a 1.3M Wikipedia web page screenshots as the corpus to answer the questions from the Natural Questions dataset. In such a text-intensive document retrieval setting, DSE shows competitive effectiveness compared to other text retrieval methods relying on parsing. For example, DSE outperforms BM25 by 17 points in top-1 retrieval accuracy. Additionally, in a mixed-modality task of slide retrieval, DSE significantly outperforms OCR text retrieval methods by over 15 points in nDCG@10. These experiments show that DSE is an effective document retrieval paradigm for diverse types of documents. Model checkpoints, code, and Wiki-SS collection will be released.
</div>

<div class="alert alert-success" role="alert"><i class="fa fa-paperclip fa-lg"></i> <b>Download URL: </b><br>
  <a href="https://aclanthology.org/2024.emnlp-main.373/">The paper: Unifying Multimodal Retrieval via Document Screenshot Embedding (Ma et al. EMNLP 2024)</a></div>

# Reference 

- Paper 
  - [arXiv Version: Unifying Multimodal Retrieval via Document Screenshot Embedding (Ma et al. arXiv 2024)](https://arxiv.org/abs/2406.11251)
  - [EMNLP Version: Unifying Multimodal Retrieval via Document Screenshot Embedding (Ma et al. EMNLP 2024)](https://aclanthology.org/2024.emnlp-main.373/)
 
- For your information
  - [A Visual Guide to LLM Agents](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-llm-agents)
  
- How to use html for alert
  - [how to use icon](http://idratherbewriting.com/documentation-theme-jekyll/mydoc_icons.html)
 
- How to use MathJax 
  - [MathJax basic tutorial and quick reference in StackExchange](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference)

