---
layout: post
title: Measuring and Narrowing the Compositionality Gap in Language Models
subtitle: Self-ask
category: RAG
tags: [LLM, RAG, Prompt]
permalink: /2025/04/10/Self_Ask/
css : /css/ForYouTubeByHyun.css
bigimg: 
  - "/img/Image/BigImages/carmel.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/monterey.jpg" : "Monterey, CA (2016)"
  - "/img/Image/BigImages/stanford_dish.jpg" : "Stanford Dish, CA (2016)"
  - "/img/Image/BigImages/marian_beach_in_sanfran.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/carmel2.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/marina.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/sanfrancisco.jpg" : "San Francisco, CA (2016)"
  
---

This post is a brief summary about the paper that I read for my study and curiosity, so I shortly arrange the content of the paper, titled [Measuring and Narrowing the Compositionality Gag in Language Models (Press et al. arXiv 2023)](https://arxiv.org/abs/2210.03350), that I read and studied. 

{% include MathJax.html %}


Self-Ask requires a one- or few-shot prompt that demonstrates how to answer the questions. 

The Self-Ask prompt starts with examples and then append the inference-time questions like "Are follow up questions needed here:". 

If LM model answert "YES" to the inference-time question, LM continously generates the question with "Follow up:" and answer to the follow-up question. 

Finally, LM has sufficiently thought of having information and then stop the generation. 

It outputs the final answer with "So the final answers is:". 

If LM outputs "No" to follow-up qeustion need, LM directly responses the question with "Completely Automatic:" 


![Press et al. arXiv 2023](//img/Image/NaturalLanguageProcessing/Papers/Pompt/2025-04-10-Self_Ask/Self-Ask_01.png)

For detailed experiment and explanation, refer to the paper, titled [Measuring and Narrowing the Compositionality Gag in Language Models (Press et al. arXiv 2023)](https://arxiv.org/abs/2210.03350)

<div class="alert alert-info" role="alert"><i class="fa fa-info-circle"></i> <b>Note(Abstract): </b>
We investigate the ability of language models to perform compositional reasoning tasks where the overall solution depends on correctly composing the answers to sub-problems. We measure how often models can correctly answer all sub-problems but not generate the overall solution, a ratio we call the compositionality gap. We evaluate this ratio by asking multi-hop questions with answers that require composing multiple facts unlikely to have been observed together during pretraining. In the GPT-3 family of models, as model size increases we show that the single-hop question answering performance improves faster than the multi-hop performance does, therefore the compositionality gap does not decrease. This surprising result suggests that while more powerful models memorize and recall more factual knowledge, they show no corresponding improvement in their ability to perform this kind of compositional reasoning. We then demonstrate how elicitive prompting (such as chain of thought) narrows the compositionality gap by reasoning explicitly. We present a new method, self-ask, that further improves on chain of thought. In our method, the model explicitly asks itself (and answers) follow-up questions before answering the initial question. We finally show that self-ask's structured prompting lets us easily plug in a search engine to answer the follow-up questions, which additionally improves accuracy.
</div>

<div class="alert alert-success" role="alert"><i class="fa fa-paperclip fa-lg"></i> <b>Download URL: </b><br>
  <a href="https://arxiv.org/abs/2210.03350">The paper: Measuring and Narrowing the Compositionality Gap in Language Models (Press et al. arXiv 2023)</a></div>

# Reference 

- Paper 
  - [arXiv Version: Measuring and Narrowing the Compositionality Gag in Language Models (Press et al. arXiv 2023)](https://arxiv.org/abs/2210.03350)
  
- How to use html for alert
  - [how to use icon](http://idratherbewriting.com/documentation-theme-jekyll/mydoc_icons.html)
 
- How to use MathJax 
  - [MathJax basic tutorial and quick reference in StackExchange](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference)

