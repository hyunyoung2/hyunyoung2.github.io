---
layout: post
title: A Survey on Employing Large Languge Models for Text-to-SQL Tasks
subtitle: Text2SQL
category: 
tags: [LLM, Prompt]
permalink: /2024/10/02/Text2SQL_Prompt/
css : /css/ForYouTubeByHyun.css
bigimg: 
  - "/img/Image/BigImages/carmel.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/monterey.jpg" : "Monterey, CA (2016)"
  - "/img/Image/BigImages/stanford_dish.jpg" : "Stanford Dish, CA (2016)"
  - "/img/Image/BigImages/marian_beach_in_sanfran.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/carmel2.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/marina.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/sanfrancisco.jpg" : "San Francisco, CA (2016)"
  
---

This post is a brief summary about the paper that I read for my study and curiosity, so I shortly arrange the content of the paper, titled [A Survey on Employing Large Language Models for Text-to-SQL Tasks (Shi et al., arXiv 2024)](https://arxiv.org/abs/2407.15186), that I read and studied. 

{% include MathJax.html %}


![Shi et al. arXiv 2024](/img/Image/NaturalLanguageProcessing/Papers/Pompt/2024-10-02-Text2SQL_Prompt/Text2SQL_Prompt1_01.png)

For detailed experiment and explanation, refer to the paper, titled [A Survey on Employing Large Language Models for Text-to-SQL Tasks (Shi et al., arXiv 2024)](https://arxiv.org/abs/2407.15186)

<div class="alert alert-success" role="alert"><i class="fa fa-paperclip fa-lg"></i> <b>Download URL: </b><br>
  <a href="https://arxiv.org/abs/2407.15186">The paper: A Survey on Employing Large Language Models for Text-to-SQL Tasks (Shi et al., arXiv 2024)</a></div>

# Reference 

- Paper 
  - [ArXiv Version: A Survey on Employing Large Language Models for Text-to-SQL Tasks (Shi et al., arXiv 2024)](https://arxiv.org/abs/2407.15186)
  
  
- For your information
  - [How-to guides Prompting](https://www.llama.com/docs/how-to-guides/prompting/)
  - [meta/meta-llama-3-8b-instruct](https://replicate.com/meta/meta-llama-3-8b-instruct/examples)
  - [meta/meta-llama-3-8b](https://replicate.com/meta/meta-llama-3-8b/examples)
  - [llama3 prompt template](https://ollama.com/library/llama3:8b-instruct-q5_K_M/blobs/8ab4849b038c)
  - [llama3 huggingface 1](https://huggingface.co/meta-llama/Meta-Llama-3-8B-Instruct)
  - [llama3 huggingface 2](https://huggingface.co/lmstudio-community/Meta-Llama-3-8B-Instruct-GGUF)
  - [llama3 recipes](https://github.com/meta-llama/llama-recipes)
  - [llama3 huggingface recipes](https://github.com/huggingface/huggingface-llama-recipes)
  - [llama2 prompt template](https://gpus.llm-utils.org/llama-2-prompt-template/)
  - [llamaIndex prompts](https://docs.llamaindex.ai/en/stable/module_guides/models/prompts/)
  - [llama2 prompt engineering](https://medium.com/@eboraks/llama-2-prompt-engineering-extracting-information-from-articles-examples-45158ff9bd23)
  - [llama2 prompt engineering experiments](https://colab.research.google.com/drive/1W_4kAZdQs_smJcwwRP0JW60IvXlVvqFV?usp=sharing)
  - [llama2 huggingface blog](https://huggingface.co/blog/llama2)
  

- How to use html for alert
  - [how to use icon](http://idratherbewriting.com/documentation-theme-jekyll/mydoc_icons.html)
 
- How to use MathJax 
  - [MathJax basic tutorial and quick reference in StackExchange](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference)

