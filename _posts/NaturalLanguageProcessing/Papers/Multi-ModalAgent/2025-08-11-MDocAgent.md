---
layout: post
title: MDocAgent - A Multi-modal Multi-Agent Framework for Document Understanding
subtitle: MDocAgent
category: Agent
tags: [Agent, Multi-modal]
permalink: /2025/08/11/MDocAgent/
css : /css/ForYouTubeByHyun.css
bigimg: 
  - "/img/Image/BigImages/carmel.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/monterey.jpg" : "Monterey, CA (2016)"
  - "/img/Image/BigImages/stanford_dish.jpg" : "Stanford Dish, CA (2016)"
  - "/img/Image/BigImages/marian_beach_in_sanfran.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/carmel2.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/marina.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/sanfrancisco.jpg" : "San Francisco, CA (2016)"
  
---

This post is a brief summary about the paper that I read for my study and curiosity, so I shortly arrange the content of the paper, titled [MDocAgent: A Multi-Modal Multi-Agent Framework For Document Understanding (Han et al. arXiv 2025)](https://arxiv.org/abs/2503.13964), that I read and studied. 

{% include MathJax.html %}


![Han et al. arXiv 2025]()


For detailed experiment and explanation, refer to the paper, titled [MDocAgent: A Multi-Modal Multi-Agent Framework For Document Understanding (Han et al. arXiv 2025)](https://arxiv.org/abs/2503.13964)

<div class="alert alert-info" role="alert"><i class="fa fa-info-circle"></i> <b>Note(Abstract): </b>

</div>

<div class="alert alert-success" role="alert"><i class="fa fa-paperclip fa-lg"></i> <b>Download URL: </b><br>
  <a href="https://arxiv.org/abs/2503.13964">The paper: MDocAgent: A Multi-Modal Multi-Agent Framework For Document Understanding (Han et al. arXiv 2025) </a></div>

# Reference 

- Paper 
  - [arXiv Version: MDocAgent: A Multi-Modal Multi-Agent Framework For Document Understanding (Han et al. arXiv 2025)](https://arxiv.org/abs/2503.13964)
   
- For your information
  - [A Visual Guide to LLM Agents](https://newsletter.maartengrootendorst.com/p/a-visual-guide-to-llm-agents)
  - [Github - Open deep research](https://github.com/langchain-ai/open_deep_research)
  - [Learning the Bitter Lessson](https://rlancemartin.github.io/2025/07/30/bitter_lesson/)
  - [Langchain - Open Deep Research](https://blog.langchain.com/open-deep-research/)
  - [Langchain - Context Engineering](https://blog.langchain.com/context-engineering-for-agents/)
  - [How we built our Multi-agent Research System](https://www.anthropic.com/engineering/multi-agent-research-system?ref=blog.langchain.com)
  - [Open Deep Research: Demoncratizing Search with Open-source Reasoning Agent. Alzubi et al, 2025 arXiv](https://arxiv.org/abs/2503.20201v1)
  - [bytedance - Deerflow](https://github.com/bytedance/deer-flow)
  - [Github - Magentic-UI](https://github.com/microsoft/magentic-ui)
  - [Magentic-UI, an experimental Human-centered web agent](https://www.microsoft.com/en-us/research/blog/magentic-ui-an-experimental-human-centered-web-agent/)
  - [What Are Agentic Workflow? Patterns Use Cases, Examples, and More](https://weaviate.io/blog/what-are-agentic-workflows)
  - [Langgraph examples RAG github](https://github.com/langchain-ai/langgraph/tree/main/examples/rag)
  - [self-Reflective RAG with LangGraph](https://blog.langchain.com/agentic-rag-with-langgraph/)

  
- How to use html for alert
  - [how to use icon](http://idratherbewriting.com/documentation-theme-jekyll/mydoc_icons.html)
 
- How to use MathJax 
  - [MathJax basic tutorial and quick reference in StackExchange](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference)

