---
layout: post
title: Demonstrate-Search-Predict - Composing retrieval and Language Models for Knowledge-intenstive NLP
subtitle: Demonstrate-Search-Predict
category: RAG
tags: [LLM, RAG]
permalink: /2025/03/16/DSP/
css : /css/ForYouTubeByHyun.css
bigimg: 
  - "/img/Image/BigImages/carmel.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/monterey.jpg" : "Monterey, CA (2016)"
  - "/img/Image/BigImages/stanford_dish.jpg" : "Stanford Dish, CA (2016)"
  - "/img/Image/BigImages/marian_beach_in_sanfran.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/carmel2.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/marina.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/sanfrancisco.jpg" : "San Francisco, CA (2016)"
  
---

This post is a brief summary about the paper that I read for my study and curiosity, so I shortly arrange the content of the paper, titled [Demonstrate-Search-Predict : Composing retreival and Language Models for knowledge-intensive NLP (Khattab et al. arXiv 2022)](https://arxiv.org/abs/2212.14024), that I read and studied. 

{% include MathJax.html %}


![Khattab et al. arXiv 2022](/img/Image/NaturalLanguageProcessing/Papers/RAG/2025-03-16-DSP/DSP_01.png)


![Khattab et al. arXiv 2022](/img/Image/NaturalLanguageProcessing/Papers/RAG/2025-03-16-DSP/DSP_02.png)


For detailed experiment and explanation, refer to the paper, titled [Demonstrate-Search-Predict : Composing retreival and Language Models for knowledge-intensive NLP (Khattab et al. arXiv 2022)](https://arxiv.org/abs/2212.14024)

<div class="alert alert-info" role="alert"><i class="fa fa-info-circle"></i> <b>Note(Abstract): </b>
Retrieval-augmented in-context learning has emerged as a powerful approach for addressing knowledge-intensive tasks using frozen language models (LM) and retrieval models (RM). Existing work has combined these in simple "retrieve-then-read" pipelines in which the RM retrieves passages that are inserted into the LM prompt. To begin to fully realize the potential of frozen LMs and RMs, we propose Demonstrate-Search-Predict (DSP), a framework that relies on passing natural language texts in sophisticated pipelines between an LM and an RM. DSP can express high-level programs that bootstrap pipeline-aware demonstrations, search for relevant passages, and generate grounded predictions, systematically breaking down problems into small transformations that the LM and RM can handle more reliably. We have written novel DSP programs for answering questions in open-domain, multi-hop, and conversational settings, establishing in early evaluations new state-of-the-art in-context learning results and delivering 37-120%, 8-39%, and 80-290% relative gains against the vanilla LM (GPT-3.5), a standard retrieve-then-read pipeline, and a contemporaneous self-ask pipeline, respectively. We release DSP at this [https URL](https://github.com/stanfordnlp/dsp).
</div>

<div class="alert alert-success" role="alert"><i class="fa fa-paperclip fa-lg"></i> <b>Download URL: </b><br>
  <a href="https://arxiv.org/abs/2212.14024">The paper: Demonstrate-Search-Predict : Composing retreival and Language Models for knowledge-intensive NLP (Khattab et al. arXiv 2022)</a></div>

# Reference 

- Paper 
  - [arXiv Version: Demonstrate-Search-Predict : Composing retreival and Language Models for knowledge-intensive NLP (Khattab et al. arXiv 2022)](https://arxiv.org/abs/2212.14024)
  
- How to use html for alert
  - [how to use icon](http://idratherbewriting.com/documentation-theme-jekyll/mydoc_icons.html)
 
- How to use MathJax 
  - [MathJax basic tutorial and quick reference in StackExchange](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference)

