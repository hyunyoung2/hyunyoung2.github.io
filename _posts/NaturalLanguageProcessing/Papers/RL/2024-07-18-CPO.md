---
layout: post
title: Contrastive Preference Optimization - Pushing the Boundaries of LLM Performance in Machine Translation
subtitle: CPO
category: LM
tags: [LLM, Feedback, Reward]
permalink: /2024/07/16/DEITA/
css : /css/ForYouTubeByHyun.css
bigimg: 
  - "/img/Image/BigImages/carmel.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/monterey.jpg" : "Monterey, CA (2016)"
  - "/img/Image/BigImages/stanford_dish.jpg" : "Stanford Dish, CA (2016)"
  - "/img/Image/BigImages/marian_beach_in_sanfran.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/carmel2.jpg" : "Carmel-by-the-Sea, CA (2016)"
  - "/img/Image/BigImages/marina.jpg" : "MRINA of San Francisco, CA (2016)"
  - "/img/Image/BigImages/sanfrancisco.jpg" : "San Francisco, CA (2016)"
  
---

This post is a brief summary about the paper that I read for my study and curiosity, so I shortly arrange the content of the paper, titled [Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation (Xu et al., ICML 2024)](https://icml.cc/virtual/2024/poster/34994), that I read and studied. 

{% include MathJax.html %}

motivated by how to learn how the model reject "goo but not pefect" tranlsation, they proposed Constrastive Preference Optimization (CPO).

CPO aims to mitigate two fundamental shortcomings of SFT. 

First FST's methodology of minimizing the discrepancy between predicted outputs and gold-standard references inherently caps model performance at the quality level of the training data.

Secondly, SFT lacks a mechanism to prevent the model from jecting the mistakes in translations. 
Whille strong translation models can produce hig-qulaity translations, they ocassionally exhibit minor errors, such as omitting parts of the translation. 

The following is about how to gather preference data to train model with CPO.

They use triplet dataset like $$ y = {y_{ref}, y_{gpt4}, y_{alma}} $$, represeting three differenct translation outputs for input $$x$$.

And then they utilized the reference-free evaluation models to score those translation.

The preferred translation is high-scoring translation and The dis-preferred translation is low-scoring translation.

![Xu et al., ICML 2024](/img/Image/NaturalLanguageProcessing/Papers/RL/2024-07-18-CPO/cpo_01.png)


As you can see the followings, DPO (direct preference optimization) is memory- or speed-inefficiency.

![Xu et al., ICML 2024](/img/Image/NaturalLanguageProcessing/Papers/RL/2024-07-18-CPO/cpo_02.png)


So, they refine the efficiency of DPO as follows: 

![Xu et al., ICML 2024](/img/Image/NaturalLanguageProcessing/Papers/RL/2024-07-18-CPO/cpo_03.png)


![Xu et al., ICML 2024](/img/Image/NaturalLanguageProcessing/Papers/RL/2024-07-18-CPO/cpo_04.png)

For detailed experiment and explanation, refer to the paper, titled [Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation (Xu et al., ICML 2024)](https://icml.cc/virtual/2024/poster/34994)

<div class="alert alert-success" role="alert"><i class="fa fa-paperclip fa-lg"></i> <b>Download URL: </b><br>
  <a href="https://icml.cc/virtual/2024/poster/34994">The paper: Constrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation (Liu et al., ICML 2024)</a></div>

# Reference 

- Paper 
  - [ArXiv Version: Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation (Xu et al., arXiv 2024)](https://arxiv.org/abs/2401.08417)
  - [ICML Version: Contrastive Preference Optimization: Pushing the Boundaries of LLM Performance in Machine Translation (Xu et al., ICML 2024)](https://icml.cc/virtual/2024/poster/34994)

- Presentation
  - [CPO presentation](https://icml.cc/media/icml-2024/Slides/34994_q9ZmJkq.pdf)

- Github
  - [DEITA](https://github.com/hkust-nlp/deita)
  
- How to use html for alert
  - [how to use icon](http://idratherbewriting.com/documentation-theme-jekyll/mydoc_icons.html)
 
- How to use MathJax 
  - [MathJax basic tutorial and quick reference in StackExchange](https://math.meta.stackexchange.com/questions/5020/mathjax-basic-tutorial-and-quick-reference)
  - [List of Greek letters and math symbols](https://www.overleaf.com/learn/latex/List_of_Greek_letters_and_math_symbols)
